{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inference on an upcoming dataset\n",
    "\n",
    "In this part, we will simulate the real deployment of the package and make inference on an upcoming dataset. We use the Adult dataset from UCI datasets which has an individual testing set.\n",
    "\n",
    "## Training models\n",
    "\n",
    "Similar to the first example, we initialize a `Trainer` and model bases, then train all models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Downloading https://archive.ics.uci.edu/static/public/2/adult.zip to /tmp/tmplxwlbz1p/data/Adult.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlluo/hdd/tabular_ensemble/tabensemb/config/user_config.py:226: UserWarning: There exists .test file(s) ['adult.test'] which should be used for final metrics. The .zip file isleft for the user to process.\n",
      "  warnings.warn(\n",
      "/home/xlluo/hdd/tabular_ensemble/tabensemb/utils/utils.py:315: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(StringIO(s), names=names, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project will be saved to /tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig\n",
      "Dataset size: 19536 6512 6513\n",
      "Data saved to /tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig (data.csv and tabular_data.csv).\n",
      "\n",
      "-------------Run PytorchTabular-------------\n",
      "\n",
      "Training Category Embedding\n",
      "Global seed set to 42\n",
      "2023-08-03 20:56:20,384 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-08-03 20:56:20,385 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "2023-08-03 20:56:20,443 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-08-03 20:56:20,464 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-08-03 20:56:21,292 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | _backbone        | CategoryEmbeddingBackbone | 18.5 K\n",
      "1 | _embedding_layer | Embedding1dLayer          | 1.4 K \n",
      "2 | head             | LinearHead                | 66    \n",
      "3 | loss             | CrossEntropyLoss          | 0     \n",
      "---------------------------------------------------------------\n",
      "20.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.0 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n",
      "Epoch: 1/300, Train loss: 0.4666, Val loss: 0.3794, Min val loss: 0.3794, Epoch time: 0.348s.\n",
      "Epoch: 20/300, Train loss: 0.3111, Val loss: 0.3181, Min val loss: 0.3174, Epoch time: 0.350s.\n",
      "Epoch: 40/300, Train loss: 0.2977, Val loss: 0.3207, Min val loss: 0.3152, Epoch time: 0.343s.\n",
      "Epoch: 60/300, Train loss: 0.2869, Val loss: 0.3249, Min val loss: 0.3152, Epoch time: 0.420s.\n",
      "Epoch: 80/300, Train loss: 0.2769, Val loss: 0.3314, Min val loss: 0.3152, Epoch time: 0.406s.\n",
      "Epoch: 100/300, Train loss: 0.2683, Val loss: 0.3416, Min val loss: 0.3152, Epoch time: 0.491s.\n",
      "Epoch: 120/300, Train loss: 0.2624, Val loss: 0.3487, Min val loss: 0.3152, Epoch time: 0.395s.\n",
      "2023-08-03 20:57:10,411 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-08-03 20:57:10,412 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/xlluo/anaconda3/envs/mlfatigue/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "Training log_loss loss: 0.28815\n",
      "Validation log_loss loss: 0.31522\n",
      "Testing log_loss loss: 0.31055\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------PytorchTabular End-------------\n",
      "\n",
      "\n",
      "-------------Run WideDeep-------------\n",
      "\n",
      "Training TabMlp\n",
      "Epoch: 1/300, Train loss: 0.5206, Val loss: 0.4274, Min val loss: 0.4274\n",
      "Epoch: 21/300, Train loss: 0.3145, Val loss: 0.3161, Min val loss: 0.3161\n",
      "Epoch: 41/300, Train loss: 0.3063, Val loss: 0.3191, Min val loss: 0.3161\n",
      "Epoch: 61/300, Train loss: 0.2980, Val loss: 0.3210, Min val loss: 0.3161\n",
      "Epoch: 81/300, Train loss: 0.2911, Val loss: 0.3225, Min val loss: 0.3161\n",
      "Epoch: 101/300, Train loss: 0.2824, Val loss: 0.3269, Min val loss: 0.3161\n",
      "Epoch: 121/300, Train loss: 0.2765, Val loss: 0.3291, Min val loss: 0.3161\n",
      "Epoch 00121: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00121: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Training log_loss loss: 0.30075\n",
      "Validation log_loss loss: 0.31724\n",
      "Testing log_loss loss: 0.31123\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------WideDeep End-------------\n",
      "\n",
      "\n",
      "-------------Run AutoGluon-------------\n",
      "\n",
      "Training Linear Regression\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig/AutoGluon/Linear Regression/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.17\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Dec 13 20:27:58 CST 2021\n",
      "Train Data Rows:    19536\n",
      "Train Data Columns: 14\n",
      "Tuning Data Rows:    6512\n",
      "Tuning Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting PipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4561.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.07 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['education', 'marital-status', 'native-country', 'occupation', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['education', 'marital-status', 'native-country', 'occupation', 'race', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "Fitting 1 L1 models ...\n",
      "Hyperparameter tuning model: LinearModel_BAG_L1 ...\n",
      "\tNo hyperparameter search space specified for LinearModel_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Fitted model: LinearModel_BAG_L1 ...\n",
      "\t0.8442\t = Validation score   (accuracy)\n",
      "\t5.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8414\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig/AutoGluon/Linear Regression/\")\n",
      "Training log_loss loss: 0.32821\n",
      "Validation log_loss loss: 0.33576\n",
      "Testing log_loss loss: 0.32834\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------AutoGluon End-------------\n",
      "\n",
      "PytorchTabular metrics\n",
      "Category Embedding 1/1\n",
      "WideDeep metrics\n",
      "TabMlp 1/1\n",
      "AutoGluon metrics\n",
      "Linear Regression 1/1\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig/trainer.pkl')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Program               Model  Training F1_SCORE  \\\n0       AutoGluon   Linear Regression           0.649959   \n1        WideDeep              TabMlp           0.694051   \n2  PytorchTabular  Category Embedding           0.708106   \n\n   Training PRECISION_SCORE  Training RECALL_SCORE  Training JACCARD_SCORE  \\\n0                  0.719298               0.592813                0.481437   \n1                  0.730498               0.661067                0.531453   \n2                  0.742191               0.677015                0.548115   \n\n   Training ACCURACY_SCORE  Training BALANCED_ACCURACY_SCORE  \\\n0                 0.846284                          0.759732   \n1                 0.859695                          0.791870   \n2                 0.865633                          0.801226   \n\n   Training COHEN_KAPPA_SCORE  Training HAMMING_LOSS  ...  \\\n0                    0.552647               0.153716  ...   \n1                    0.603321               0.140305  ...   \n2                    0.621075               0.134367  ...   \n\n   Validation ACCURACY_SCORE  Validation BALANCED_ACCURACY_SCORE  \\\n0                   0.841370                            0.755397   \n1                   0.852426                            0.783820   \n2                   0.851044                            0.780948   \n\n   Validation COHEN_KAPPA_SCORE  Validation HAMMING_LOSS  \\\n0                      0.540607                 0.158630   \n1                      0.584325                 0.147574   \n2                      0.579583                 0.148956   \n\n   Validation MATTHEWS_CORRCOEF  Validation ZERO_ONE_LOSS  \\\n0                      0.544061                  0.158630   \n1                      0.585265                  0.147574   \n2                      0.580653                  0.148956   \n\n   Validation ROC_AUC_SCORE  Validation LOG_LOSS  Validation BRIER_SCORE_LOSS  \\\n0                  0.896542             0.335764                     0.108401   \n1                  0.908941             0.317243                     0.101578   \n2                  0.909818             0.315222                     0.101306   \n\n   Validation AVERAGE_PRECISION_SCORE  \n0                            0.848356  \n1                            0.868427  \n2                            0.869300  \n\n[3 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Model</th>\n      <th>Training F1_SCORE</th>\n      <th>Training PRECISION_SCORE</th>\n      <th>Training RECALL_SCORE</th>\n      <th>Training JACCARD_SCORE</th>\n      <th>Training ACCURACY_SCORE</th>\n      <th>Training BALANCED_ACCURACY_SCORE</th>\n      <th>Training COHEN_KAPPA_SCORE</th>\n      <th>Training HAMMING_LOSS</th>\n      <th>...</th>\n      <th>Validation ACCURACY_SCORE</th>\n      <th>Validation BALANCED_ACCURACY_SCORE</th>\n      <th>Validation COHEN_KAPPA_SCORE</th>\n      <th>Validation HAMMING_LOSS</th>\n      <th>Validation MATTHEWS_CORRCOEF</th>\n      <th>Validation ZERO_ONE_LOSS</th>\n      <th>Validation ROC_AUC_SCORE</th>\n      <th>Validation LOG_LOSS</th>\n      <th>Validation BRIER_SCORE_LOSS</th>\n      <th>Validation AVERAGE_PRECISION_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AutoGluon</td>\n      <td>Linear Regression</td>\n      <td>0.649959</td>\n      <td>0.719298</td>\n      <td>0.592813</td>\n      <td>0.481437</td>\n      <td>0.846284</td>\n      <td>0.759732</td>\n      <td>0.552647</td>\n      <td>0.153716</td>\n      <td>...</td>\n      <td>0.841370</td>\n      <td>0.755397</td>\n      <td>0.540607</td>\n      <td>0.158630</td>\n      <td>0.544061</td>\n      <td>0.158630</td>\n      <td>0.896542</td>\n      <td>0.335764</td>\n      <td>0.108401</td>\n      <td>0.848356</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WideDeep</td>\n      <td>TabMlp</td>\n      <td>0.694051</td>\n      <td>0.730498</td>\n      <td>0.661067</td>\n      <td>0.531453</td>\n      <td>0.859695</td>\n      <td>0.791870</td>\n      <td>0.603321</td>\n      <td>0.140305</td>\n      <td>...</td>\n      <td>0.852426</td>\n      <td>0.783820</td>\n      <td>0.584325</td>\n      <td>0.147574</td>\n      <td>0.585265</td>\n      <td>0.147574</td>\n      <td>0.908941</td>\n      <td>0.317243</td>\n      <td>0.101578</td>\n      <td>0.868427</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PytorchTabular</td>\n      <td>Category Embedding</td>\n      <td>0.708106</td>\n      <td>0.742191</td>\n      <td>0.677015</td>\n      <td>0.548115</td>\n      <td>0.865633</td>\n      <td>0.801226</td>\n      <td>0.621075</td>\n      <td>0.134367</td>\n      <td>...</td>\n      <td>0.851044</td>\n      <td>0.780948</td>\n      <td>0.579583</td>\n      <td>0.148956</td>\n      <td>0.580653</td>\n      <td>0.148956</td>\n      <td>0.909818</td>\n      <td>0.315222</td>\n      <td>0.101306</td>\n      <td>0.869300</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 44 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tabensemb.trainer import Trainer\n",
    "from tabensemb.model import *\n",
    "import tabensemb\n",
    "from tabensemb.config import UserConfig\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "temp_path = TemporaryDirectory()\n",
    "tabensemb.setting[\"default_output_path\"] = os.path.join(temp_path.name, \"output\")\n",
    "tabensemb.setting[\"default_config_path\"] = os.path.join(temp_path.name, \"configs\")\n",
    "tabensemb.setting[\"default_data_path\"] = os.path.join(temp_path.name, \"data\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "trainer = Trainer(device=device)\n",
    "cfg = UserConfig.from_uci(\"Adult\", sep=\", \")\n",
    "trainer.load_config(cfg)\n",
    "trainer.load_data()\n",
    "models = [\n",
    "    PytorchTabular(trainer, model_subset=[\"Category Embedding\"]),\n",
    "    WideDeep(trainer, model_subset=[\"TabMlp\"]),\n",
    "    AutoGluon(trainer, model_subset=[\"Linear Regression\"]),\n",
    "]\n",
    "trainer.add_modelbases(models)\n",
    "trainer.train(stderr_to_stdout=True)\n",
    "trainer.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Optional*: Use the following line, we can run k-fold cross-validation and check the leaderboard.\n",
    "\n",
    "```python\n",
    "trainer.get_leaderboard(cross_validation=10, split_type=\"cv\", stderr_to_stdout=True)\n",
    "```\n",
    "\n",
    "**Remark**: `split_type` can be `random`, which means that the dataset is randomly split according to the given `split_ratio` in the configuration and different random seeds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selecting and storing a model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the leaderboard, we can check the performance of each model and select one of the models for deployment. Say we want to choose `Linear Regression` from `AutoGluon`, we detach the model from the heavy `trainer`. It is also stored locally in a separate directory."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmplxwlbz1p/output/adult/2023-08-03-20-56-18-0_UserInputConfig-I1/trainer.pkl')\n"
     ]
    }
   ],
   "source": [
    "trainer_of_one_model = trainer.detach_model(program=\"AutoGluon\", model_name=\"Linear Regression\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The detached trainer now has only one model base."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tabensemb.model.autogluon.AutoGluon at 0x7f0954828c70>]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model bases of the detached trainer\n",
    "trainer_of_one_model.modelbases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "('Linear Regression',\n <autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f09803be760>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model in the model base\n",
    "trainer_of_one_model.get_modelbase(\"AutoGluon_Linear Regression\").model[\"Linear Regression\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the `Trainer` containing a single model stores in a seperate directory. Assume that we want to load the local trainer in a separate script for inference. In the following line, the argument `path` of `load_trainer` is the path to `trainer.pkl`, which is already printed when detaching the model or training the model bases. Here we just use the directory of the detached trainer `trainer_of_one_model`.\n",
    "\n",
    "**Remark**: You can move the directory to any other places (or other devices if the version of the package and the environment are all consistent) and rename the folder. `tabensemb` automatically configures the path."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from tabensemb.trainer import load_trainer\n",
    "\n",
    "trainer = load_trainer(path=os.path.join(trainer_of_one_model.project_root, \"trainer.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "('Linear Regression',\n <autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f0954ba9fd0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_modelbase(\"AutoGluon_Linear Regression\").model[\"Linear Regression\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "\n",
    "Assume that we have a new `DataFrame` representing an upcoming dataset. For demonstration, we use the testing set here. The classification target is ordinal encoded by `trainer.datamodule.label_ordinal_encoder`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 1, ..., 1, 0, 0])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = trainer.df.loc[trainer.test_indices, :]\n",
    "truth = trainer.df.loc[trainer.test_indices, trainer.label_name].values.flatten()\n",
    "truth"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the functionality of the model base to do inference. The returned result should be"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['<=50K'],\n       ['<=50K'],\n       ['>50K'],\n       ...,\n       ['>50K'],\n       ['<=50K'],\n       ['<=50K']], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = trainer.get_modelbase(\"AutoGluon_Linear Regression\").predict(df, model_name=\"Linear Regression\")\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see the F1 score on the \"new\" (testing) dataset is the same as that in the above leaderboard. The result should be ordinal-encoded first to calculate metrics. We provide `DataModule.label_categories_transform` to achieve this (and `DataModule.label_categories_inverse_transform` to do inverse transform).\n",
    "\n",
    "The `auto_metric_sklearn` automatically calculates different kinds of `sklearn.metrics`, which is extremely useful for classification tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6615652173913042, array([0.66156522]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabensemb.utils import auto_metric_sklearn\n",
    "\n",
    "encoded_result = trainer.datamodule.label_categories_transform(pd.DataFrame(result, columns=trainer.label_name)).values\n",
    "# You can also use trainer.datamodule.label_ordinal_encoder.transform(result) to get the same result.\n",
    "auto_metric_sklearn(truth, encoded_result, \"f1_score\", \"binary\"), trainer.leaderboard.loc[trainer.leaderboard[\"Model\"]==\"Linear Regression\", \"Testing F1_SCORE\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference on the individual testing set\n",
    "\n",
    "When loading from UCI datasets, `UserConfig.from_uci` finds that a testing data exists, so the downloaded .zip file is not removed. We can load the archive using `zipfile`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['Index', 'adult.data', 'adult.names', 'adult.test', 'old.adult.names']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zipf = zipfile.ZipFile(os.path.join(tabensemb.setting[\"default_data_path\"], \"Adult.zip\"))\n",
    "zipf.namelist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now check the content of `adult.text`. It is a .csv-like file, just like the `adult.data` file but has an additional row at the front, and an additional \".\" at the end of each line."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1x3 Cross validator\n",
      "25, Private, 226802, 11th, 7, Never-married, Machine-op-inspct, Own-child, Black, Male, 0, 0, 40, United-States, <=50K.\n",
      "38, Private, 89814, HS-grad, 9, Married-civ-spouse, Farming-fishing, Husband, White, Male, 0, 0, 50, United-States, <=50K.\n",
      "28, Local-gov, 336951, Assoc-acdm, 12, Married-civ-spouse, Protective-serv, Husband, White, Male, 0, 0, 40, United-States, >50K.\n",
      "44, Private, 160323, Some-college, 10, Married-civ-spouse, Machine-op-inspct, Husband, Black, Male, 7688, 0\n"
     ]
    }
   ],
   "source": [
    "file = zipf.read(\"adult.test\").decode()\n",
    "print(file[:500])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We provide the `str_to_dataframe` function that translate the string object to a `DataFrame` and replace illegal values by `np.nan`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlluo/hdd/tabular_ensemble/tabensemb/utils/utils.py:315: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(StringIO(s), names=names, sep=sep)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       age     workclass  fnlwgt     education  education-num  \\\n0       25       Private  226802          11th              7   \n1       38       Private   89814       HS-grad              9   \n2       28     Local-gov  336951    Assoc-acdm             12   \n3       44       Private  160323  Some-college             10   \n4       18             ?  103497  Some-college             10   \n...    ...           ...     ...           ...            ...   \n16276   39       Private  215419     Bachelors             13   \n16277   64             ?  321403       HS-grad              9   \n16278   38       Private  374983     Bachelors             13   \n16279   44       Private   83891     Bachelors             13   \n16280   35  Self-emp-inc  182148     Bachelors             13   \n\n           marital-status         occupation    relationship  \\\n0           Never-married  Machine-op-inspct       Own-child   \n1      Married-civ-spouse    Farming-fishing         Husband   \n2      Married-civ-spouse    Protective-serv         Husband   \n3      Married-civ-spouse  Machine-op-inspct         Husband   \n4           Never-married                  ?       Own-child   \n...                   ...                ...             ...   \n16276            Divorced     Prof-specialty   Not-in-family   \n16277             Widowed                  ?  Other-relative   \n16278  Married-civ-spouse     Prof-specialty         Husband   \n16279            Divorced       Adm-clerical       Own-child   \n16280  Married-civ-spouse    Exec-managerial         Husband   \n\n                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n0                   Black    Male             0             0              40   \n1                   White    Male             0             0              50   \n2                   White    Male             0             0              40   \n3                   Black    Male          7688             0              40   \n4                   White  Female             0             0              30   \n...                   ...     ...           ...           ...             ...   \n16276               White  Female             0             0              36   \n16277               Black    Male             0             0              40   \n16278               White    Male             0             0              50   \n16279  Asian-Pac-Islander    Male          5455             0              40   \n16280               White    Male             0             0              60   \n\n      native-country  class  \n0      United-States  <=50K  \n1      United-States  <=50K  \n2      United-States   >50K  \n3      United-States   >50K  \n4      United-States  <=50K  \n...              ...    ...  \n16276  United-States  <=50K  \n16277  United-States  <=50K  \n16278  United-States  <=50K  \n16279  United-States  <=50K  \n16280  United-States   >50K  \n\n[16281 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>Private</td>\n      <td>226802</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Never-married</td>\n      <td>Machine-op-inspct</td>\n      <td>Own-child</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>89814</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>Local-gov</td>\n      <td>336951</td>\n      <td>Assoc-acdm</td>\n      <td>12</td>\n      <td>Married-civ-spouse</td>\n      <td>Protective-serv</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>Private</td>\n      <td>160323</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Machine-op-inspct</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>7688</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>?</td>\n      <td>103497</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>?</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16276</th>\n      <td>39</td>\n      <td>Private</td>\n      <td>215419</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Divorced</td>\n      <td>Prof-specialty</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>16277</th>\n      <td>64</td>\n      <td>?</td>\n      <td>321403</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Widowed</td>\n      <td>?</td>\n      <td>Other-relative</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>16278</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>374983</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>16279</th>\n      <td>44</td>\n      <td>Private</td>\n      <td>83891</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Divorced</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>Asian-Pac-Islander</td>\n      <td>Male</td>\n      <td>5455</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>16280</th>\n      <td>35</td>\n      <td>Self-emp-inc</td>\n      <td>182148</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n<p>16281 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabensemb.utils import str_to_dataframe\n",
    "\n",
    "file = file.replace(\"|1x3 Cross validator\\n\",\"\").replace(\".\\n\", \"\\n\")\n",
    "testing_df = str_to_dataframe(file, sep=\", \", names=trainer.df.columns, check_nan_on=trainer.cont_feature_names)\n",
    "testing_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inference is similar."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['<=50K'],\n       ['<=50K'],\n       ['<=50K'],\n       ...,\n       ['>50K'],\n       ['<=50K'],\n       ['>50K']], dtype=object)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = trainer.get_modelbase(\"AutoGluon_Linear Regression\").predict(testing_df, model_name=\"Linear Regression\")\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both the truth and the result require to be ordinal-encoded to calculate metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6438414547520955, 0.7573179597871491)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_truth = trainer.datamodule.label_categories_transform(testing_df[trainer.label_name]).values\n",
    "encoded_result = trainer.datamodule.label_categories_transform(pd.DataFrame(result, columns=trainer.label_name)).values\n",
    "auto_metric_sklearn(encoded_truth, encoded_result, \"f1_score\", \"binary\"), auto_metric_sklearn(encoded_truth, encoded_result, \"roc_auc_score\", \"binary\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}