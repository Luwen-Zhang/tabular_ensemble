{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basics of running benchmarks\n",
    "\n",
    "Tabular Ensemble (`tabensemb`) is a benchmark platform for tabular prediction tasks. We support three well-established model bases as baselines:\n",
    "\n",
    "* `autogluon`: [Link](https://github.com/autogluon/autogluon)\n",
    "\n",
    "* `pytorch_widedeep`: [Link](https://github.com/jrzaurin/pytorch-widedeep)\n",
    "\n",
    "* `pytorch_tabular`: [Link](https://github.com/manujosephv/pytorch_tabular)\n",
    "\n",
    "Users are able to run benchmarks on customized datasets using customized preprocessing steps, and implement customized models in the framework to run and compare their performance with baselines within a consistent procedure.\n",
    "\n",
    "In this part, minimum examples on regression, binary classification, and multiclass classification are performed to show the basic functionality of the package."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading packages\n",
    "\n",
    "First, import necessary modules. Then check the validity of `CUDA` and determine the training device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tabensemb.trainer import Trainer\n",
    "from tabensemb.model import *\n",
    "from tabensemb.config import UserConfig\n",
    "import tabensemb\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`tabensemb` uses paths relative to the current directory. For different IDEs (PyCharm, VSCode, etc.), the directory can be different. Set default paths to desired ones.\n",
    "\n",
    "* tabensemb.setting[\"default_output_path\"]: It will be used to save results. This path will be created if not exist.\n",
    "* tabensemb.setting[\"default_config_path\"]: It should be the path to configuration files (See \"Using a configuration file\" for its case).\n",
    "* tabensemb.setting[\"default_config_path\"]: It should be the path to data files. It will also be used to save downloaded datasets (See \"Using a configuration file\" for its case).\n",
    "\n",
    "In this notebook, we use a temporary directory for cleanliness. Change `temp_path.name` to your own directory."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "temp_path = TemporaryDirectory()\n",
    "tabensemb.setting[\"default_output_path\"] = os.path.join(temp_path.name, \"output\")\n",
    "tabensemb.setting[\"default_config_path\"] = os.path.join(temp_path.name, \"configs\")\n",
    "tabensemb.setting[\"default_data_path\"] = os.path.join(temp_path.name, \"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuring a `Trainer`\n",
    "\n",
    "Create a `Trainer`, which acts as a bridge of data and models and provides some useful ultilities."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an example, we use the Auto MPG dataset from [UCI datasets](https://archive.ics.uci.edu/datasets) . We can import UCI datasets through the `UserConfig` class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://archive.ics.uci.edu/static/public/9/auto+mpg.zip to /tmp/tmpqij93vth/data/Auto MPG.zip\n",
      "cylinders is Integer and will be treated as a continuous feature.\n",
      "model_year is Integer and will be treated as a continuous feature.\n",
      "origin is Integer and will be treated as a continuous feature.\n",
      "Unknown values are detected in ['horsepower']. They will be treated as np.nan.\n",
      "Project will be saved to /tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig\n"
     ]
    }
   ],
   "source": [
    "cfg = UserConfig.from_uci(\"Auto MPG\", sep=\"\\s+\")\n",
    "trainer.load_config(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Optional*: We provide a useful `Logging` class to record all outputs to a file located in the above project root, so that users can review the training process. This step is optional but we strongly recommend using it.\n",
    "\n",
    "`Trainer.project_root` is the output directory of the `trainer`, and here we log all `stdout` and `stderr` to `log.txt` in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tabensemb.utils import Logging\n",
    "log = Logging()\n",
    "log.enter(os.path.join(trainer.project_root, \"log.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Viewing configurations\n",
    "\n",
    "We can view the summary of the current environment, including devices/Python version, the loaded configuration, and global settings of `tabensemb`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:\n",
      "{\n",
      "\t'System': 'Linux',\n",
      "\t'Node name': 'xlluo-WS',\n",
      "\t'System release': '5.15.6-custom',\n",
      "\t'System version': '#1 SMP Mon Dec 13 20:27:58 CST 2021',\n",
      "\t'Machine architecture': 'x86_64',\n",
      "\t'Processor architecture': 'x86_64',\n",
      "\t'Processor model': '11th Gen Intel(R) Core(TM) i9-11900K @ 3.50GHz',\n",
      "\t'Physical cores': 8,\n",
      "\t'Total cores': 16,\n",
      "\t'Max core frequency': '5150.00Mhz',\n",
      "\t'Total memory': '31.20GB',\n",
      "\t'Python version': '3.8.17',\n",
      "\t'Python implementation': 'CPython',\n",
      "\t'Python compiler': 'GCC 11.2.0',\n",
      "\t'Cuda availability': True,\n",
      "\t'GPU devices': [\n",
      "\t\t'NVIDIA GeForce RTX 3090'\n",
      "\t]\n",
      "}\n",
      "Configurations:\n",
      "{\n",
      "\t'database': 'auto-mpg',\n",
      "\t'task': 'regression',\n",
      "\t'loss': None,\n",
      "\t'bayes_opt': False,\n",
      "\t'bayes_calls': 50,\n",
      "\t'bayes_epoch': 30,\n",
      "\t'patience': 100,\n",
      "\t'epoch': 300,\n",
      "\t'lr': 0.001,\n",
      "\t'weight_decay': 1e-09,\n",
      "\t'batch_size': 1024,\n",
      "\t'layers': [\n",
      "\t\t64,\n",
      "\t\t128,\n",
      "\t\t256,\n",
      "\t\t128,\n",
      "\t\t64\n",
      "\t],\n",
      "\t'SPACEs': {\n",
      "\t\t'lr': {\n",
      "\t\t\t'type': 'Real',\n",
      "\t\t\t'low': 0.0001,\n",
      "\t\t\t'high': 0.05,\n",
      "\t\t\t'prior': 'log-uniform'\n",
      "\t\t},\n",
      "\t\t'weight_decay': {\n",
      "\t\t\t'type': 'Real',\n",
      "\t\t\t'low': 1e-09,\n",
      "\t\t\t'high': 0.05,\n",
      "\t\t\t'prior': 'log-uniform'\n",
      "\t\t},\n",
      "\t\t'batch_size': {\n",
      "\t\t\t'type': 'Categorical',\n",
      "\t\t\t'categories': [\n",
      "\t\t\t\t64,\n",
      "\t\t\t\t128,\n",
      "\t\t\t\t256,\n",
      "\t\t\t\t512,\n",
      "\t\t\t\t1024,\n",
      "\t\t\t\t2048\n",
      "\t\t\t]\n",
      "\t\t}\n",
      "\t},\n",
      "\t'data_splitter': 'RandomSplitter',\n",
      "\t'split_ratio': [\n",
      "\t\t0.6,\n",
      "\t\t0.2,\n",
      "\t\t0.2\n",
      "\t],\n",
      "\t'data_imputer': 'MissForestImputer',\n",
      "\t'data_processors': [\n",
      "\t\t(\n",
      "\t\t\t'CategoricalOrdinalEncoder',\n",
      "\t\t\t{\n",
      "\t\t\t}\n",
      "\t\t),\n",
      "\t\t(\n",
      "\t\t\t'NaNFeatureRemover',\n",
      "\t\t\t{\n",
      "\t\t\t}\n",
      "\t\t),\n",
      "\t\t(\n",
      "\t\t\t'VarianceFeatureSelector',\n",
      "\t\t\t{\n",
      "\t\t\t\t'thres': 1\n",
      "\t\t\t}\n",
      "\t\t),\n",
      "\t\t(\n",
      "\t\t\t'StandardScaler',\n",
      "\t\t\t{\n",
      "\t\t\t}\n",
      "\t\t)\n",
      "\t],\n",
      "\t'data_derivers': [\n",
      "\t],\n",
      "\t'feature_names_type': {\n",
      "\t\t'displacement': 0,\n",
      "\t\t'cylinders': 0,\n",
      "\t\t'horsepower': 0,\n",
      "\t\t'weight': 0,\n",
      "\t\t'acceleration': 0,\n",
      "\t\t'model_year': 0,\n",
      "\t\t'origin': 0\n",
      "\t},\n",
      "\t'categorical_feature_names': [\n",
      "\t],\n",
      "\t'feature_types': [\n",
      "\t\t'Continuous',\n",
      "\t\t'Categorical',\n",
      "\t\t'Derived'\n",
      "\t],\n",
      "\t'label_name': [\n",
      "\t\t'mpg'\n",
      "\t]\n",
      "}\n",
      "Global settings:\n",
      "{\n",
      "\t'random_seed': 42,\n",
      "\t'low_memory': True,\n",
      "\t'verbose_per_epoch': 20,\n",
      "\t'test_with_no_grad': True,\n",
      "\t'debug_mode': False,\n",
      "\t'default_output_path': '/tmp/tmpqij93vth/output',\n",
      "\t'default_config_path': '/tmp/tmpqij93vth/configs',\n",
      "\t'default_data_path': '/tmp/tmpqij93vth/data',\n",
      "\t'warn_nan_metric': True,\n",
      "\t'raise_inconsistent_inferred_task': False\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trainer.summarize_setting()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading data\n",
    "\n",
    "In the configuration summary above, the dataset file is defined by \"database\" under the `Configurations` category. `Trainer.load_data` automatically searches the file in the current directory and `tabensemb.setting[\"default_data_path\"]`. Now, load the Auto MPG dataset into the `Trainer`. It will process the dataset and get ready for training models:\n",
    "\n",
    "1. Data splitting (training/validation/testing sets)\n",
    "2. Data imputation\n",
    "3. Data augmentation (for features)\n",
    "4. Data processing\n",
    "    * Data augmentation (for data points)\n",
    "    * Data filtering\n",
    "    * Feature selection\n",
    "    * Categorical encoding\n",
    "    * Data scaling\n",
    "    * etc.\n",
    "5. Data augmentation (for features, especially multi-modal features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 238 80 80\n",
      "Data saved to /tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig (data.csv and tabular_data.csv).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlluo/hdd/tabular_ensemble/tabensemb/data/datamodule.py:455: UserWarning: The inferred task multiclass is not consistent with the selected task regression. Using the selected task.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing model bases\n",
    "\n",
    "Initialize model bases and add them to the `Trainer`. We only choose a subset of models in each model base for demonstration by passing the `model_subset` argument (without it, all available models will be trained)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    PytorchTabular(trainer, model_subset=[\"Category Embedding\"]),\n",
    "    WideDeep(trainer, model_subset=[\"TabMlp\"]),\n",
    "    AutoGluon(trainer, model_subset=[\"Linear Regression\"]),\n",
    "]\n",
    "trainer.add_modelbases(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Start training\n",
    "\n",
    "Now train the model bases. The argument `stderr_to_stdout` will redirect warnings and loggings to `stdout` and makes records in the notebook clean.\n",
    "\n",
    "*Optional*: Use the following line, we can run k-fold cross-validation to get the leaderboard, where k is `cross_validation`.\n",
    "\n",
    "```python\n",
    "trainer.get_leaderboard(cross_validation=10, split_type=\"cv\", stderr_to_stdout=True)\n",
    "```\n",
    "\n",
    "**Remark**: `split_type` can be `random`, which means that the dataset is randomly split according to the given `split_ratio` in the configuration and different random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------Run PytorchTabular-------------\n",
      "\n",
      "Training Category Embedding\n",
      "Global seed set to 42\n",
      "2023-08-03 20:50:48,586 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-08-03 20:50:48,586 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-08-03 20:50:48,595 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-08-03 20:50:48,606 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-08-03 20:50:49,530 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | _backbone        | CategoryEmbeddingBackbone | 11.4 K\n",
      "1 | _embedding_layer | Embedding1dLayer          | 14    \n",
      "2 | head             | LinearHead                | 33    \n",
      "3 | loss             | MSELoss                   | 0     \n",
      "---------------------------------------------------------------\n",
      "11.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "Epoch: 1/300, Train loss: 36.9995, Val loss: 33.2870, Min val loss: 33.2870, Epoch time: 0.011s.\n",
      "Epoch: 20/300, Train loss: 4.5338, Val loss: 2.7738, Min val loss: 2.7738, Epoch time: 0.014s.\n",
      "Epoch: 40/300, Train loss: 2.1565, Val loss: 2.0902, Min val loss: 2.0902, Epoch time: 0.013s.\n",
      "Epoch: 60/300, Train loss: 1.3352, Val loss: 1.2223, Min val loss: 1.2223, Epoch time: 0.010s.\n",
      "Epoch: 80/300, Train loss: 1.0861, Val loss: 1.0255, Min val loss: 1.0255, Epoch time: 0.012s.\n",
      "Epoch: 100/300, Train loss: 0.7876, Val loss: 0.9221, Min val loss: 0.9221, Epoch time: 0.009s.\n",
      "Epoch: 120/300, Train loss: 0.6533, Val loss: 0.7793, Min val loss: 0.7793, Epoch time: 0.016s.\n",
      "Epoch: 140/300, Train loss: 0.6393, Val loss: 0.6952, Min val loss: 0.6952, Epoch time: 0.015s.\n",
      "Epoch: 160/300, Train loss: 0.5889, Val loss: 0.6062, Min val loss: 0.6062, Epoch time: 0.011s.\n",
      "Epoch: 180/300, Train loss: 0.4765, Val loss: 0.4732, Min val loss: 0.4682, Epoch time: 0.009s.\n",
      "Epoch: 200/300, Train loss: 0.3316, Val loss: 0.3962, Min val loss: 0.3962, Epoch time: 0.012s.\n",
      "Epoch: 220/300, Train loss: 0.3417, Val loss: 0.3266, Min val loss: 0.3266, Epoch time: 0.010s.\n",
      "Epoch: 240/300, Train loss: 0.3357, Val loss: 0.2873, Min val loss: 0.2813, Epoch time: 0.017s.\n",
      "Epoch: 260/300, Train loss: 0.2315, Val loss: 0.2299, Min val loss: 0.2216, Epoch time: 0.009s.\n",
      "Epoch: 280/300, Train loss: 0.1948, Val loss: 0.1863, Min val loss: 0.1863, Epoch time: 0.010s.\n",
      "Epoch: 300/300, Train loss: 0.1871, Val loss: 0.1709, Min val loss: 0.1679, Epoch time: 0.010s.\n",
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n",
      "2023-08-03 20:50:55,837 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-08-03 20:50:55,837 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/xlluo/anaconda3/envs/mlfatigue/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "Training mse loss: 0.12816\n",
      "Validation mse loss: 0.16785\n",
      "Testing mse loss: 0.25842\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------PytorchTabular End-------------\n",
      "\n",
      "\n",
      "-------------Run WideDeep-------------\n",
      "\n",
      "Training TabMlp\n",
      "Epoch: 1/300, Train loss: 31.3699, Val loss: 31.3902, Min val loss: 31.3902\n",
      "Epoch: 21/300, Train loss: 4.7284, Val loss: 4.3482, Min val loss: 4.3482\n",
      "Epoch: 41/300, Train loss: 2.1918, Val loss: 2.1015, Min val loss: 2.1015\n",
      "Epoch: 61/300, Train loss: 1.2278, Val loss: 1.2459, Min val loss: 1.2459\n",
      "Epoch: 81/300, Train loss: 1.0096, Val loss: 0.9937, Min val loss: 0.9937\n",
      "Epoch: 101/300, Train loss: 0.8193, Val loss: 0.7567, Min val loss: 0.7567\n",
      "Epoch: 121/300, Train loss: 0.7792, Val loss: 0.7089, Min val loss: 0.7049\n",
      "Epoch: 141/300, Train loss: 0.7625, Val loss: 0.6014, Min val loss: 0.6014\n",
      "Epoch: 161/300, Train loss: 0.7034, Val loss: 0.5495, Min val loss: 0.5495\n",
      "Epoch: 181/300, Train loss: 0.6561, Val loss: 0.5199, Min val loss: 0.5059\n",
      "Epoch: 201/300, Train loss: 0.6215, Val loss: 0.4681, Min val loss: 0.4681\n",
      "Epoch: 221/300, Train loss: 0.4670, Val loss: 0.4444, Min val loss: 0.4444\n",
      "Epoch: 241/300, Train loss: 0.5490, Val loss: 0.3973, Min val loss: 0.3842\n",
      "Epoch: 261/300, Train loss: 0.5278, Val loss: 0.3510, Min val loss: 0.3510\n",
      "Epoch: 281/300, Train loss: 0.4117, Val loss: 0.3355, Min val loss: 0.3255\n",
      "Restoring model weights from the end of the best epoch\n",
      "Training mse loss: 0.25748\n",
      "Validation mse loss: 0.28530\n",
      "Testing mse loss: 0.27732\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------WideDeep End-------------\n",
      "\n",
      "\n",
      "-------------Run AutoGluon-------------\n",
      "\n",
      "Training Linear Regression\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig/AutoGluon/Linear Regression/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.17\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Dec 13 20:27:58 CST 2021\n",
      "Train Data Rows:    238\n",
      "Train Data Columns: 7\n",
      "Tuning Data Rows:    80\n",
      "Tuning Data Columns: 7\n",
      "Label Column: mpg\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting PipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5249.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['displacement', 'cylinders', 'horsepower', 'weight', 'acceleration']\n",
      "\t\t('int', [])   : 2 | ['model_year', 'origin']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['displacement', 'cylinders', 'horsepower', 'weight', 'acceleration']\n",
      "\t\t('int', [])   : 2 | ['model_year', 'origin']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "Fitting 1 L1 models ...\n",
      "Hyperparameter tuning model: LinearModel_BAG_L1 ...\n",
      "\tNo hyperparameter search space specified for LinearModel_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Fitted model: LinearModel_BAG_L1 ...\n",
      "\t-0.2645\t = Validation score   (-mean_squared_error)\n",
      "\t4.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.2436\t = Validation score   (-mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig/AutoGluon/Linear Regression/\")\n",
      "Training mse loss: 0.24224\n",
      "Validation mse loss: 0.24361\n",
      "Testing mse loss: 0.32878\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------AutoGluon End-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(stderr_to_stdout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After training finishes, check the leaderboard to see their performance.\n",
    "\n",
    "Metrics used in leaderboards can be found in `tabensemb.utils.utils.REGRESSION_METRICS/BINARY_METRICS/MULTICLASS_METRICS`. Most of the metrics are from `sklearn.metrics`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchTabular metrics\n",
      "Category Embedding 1/1\n",
      "WideDeep metrics\n",
      "TabMlp 1/1\n",
      "AutoGluon metrics\n",
      "Linear Regression 1/1\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/auto-mpg/2023-08-03-20-50-47-0_UserInputConfig/trainer.pkl')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Program               Model  Training RMSE  Training MSE  \\\n0  PytorchTabular  Category Embedding       0.357999      0.128164   \n1        WideDeep              TabMlp       0.507421      0.257476   \n2       AutoGluon   Linear Regression       0.492177      0.242239   \n\n   Training MAE  Training MAPE  Training R2  Training MEDIAN_ABSOLUTE_ERROR  \\\n0      0.269086       0.049639     0.954546                        0.201576   \n1      0.370808       0.070433     0.908686                        0.272293   \n2      0.360783       0.066718     0.914090                        0.239442   \n\n   Training EXPLAINED_VARIANCE_SCORE  Testing RMSE  ...  Testing R2  \\\n0                           0.961487      0.508347  ...    0.916572   \n1                           0.915921      0.526612  ...    0.910470   \n2                           0.914090      0.573398  ...    0.893855   \n\n   Testing MEDIAN_ABSOLUTE_ERROR  Testing EXPLAINED_VARIANCE_SCORE  \\\n0                       0.254563                          0.930668   \n1                       0.323880                          0.921738   \n2                       0.373830                          0.894028   \n\n   Validation RMSE  Validation MSE  Validation MAE  Validation MAPE  \\\n0         0.409699        0.167853        0.325146         0.062197   \n1         0.534130        0.285295        0.419972         0.081513   \n2         0.493568        0.243609        0.387519         0.073325   \n\n   Validation R2  Validation MEDIAN_ABSOLUTE_ERROR  \\\n0       0.941091                          0.242850   \n1       0.899874                          0.354550   \n2       0.914504                          0.327456   \n\n   Validation EXPLAINED_VARIANCE_SCORE  \n0                             0.947143  \n1                             0.905366  \n2                             0.914646  \n\n[3 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Model</th>\n      <th>Training RMSE</th>\n      <th>Training MSE</th>\n      <th>Training MAE</th>\n      <th>Training MAPE</th>\n      <th>Training R2</th>\n      <th>Training MEDIAN_ABSOLUTE_ERROR</th>\n      <th>Training EXPLAINED_VARIANCE_SCORE</th>\n      <th>Testing RMSE</th>\n      <th>...</th>\n      <th>Testing R2</th>\n      <th>Testing MEDIAN_ABSOLUTE_ERROR</th>\n      <th>Testing EXPLAINED_VARIANCE_SCORE</th>\n      <th>Validation RMSE</th>\n      <th>Validation MSE</th>\n      <th>Validation MAE</th>\n      <th>Validation MAPE</th>\n      <th>Validation R2</th>\n      <th>Validation MEDIAN_ABSOLUTE_ERROR</th>\n      <th>Validation EXPLAINED_VARIANCE_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PytorchTabular</td>\n      <td>Category Embedding</td>\n      <td>0.357999</td>\n      <td>0.128164</td>\n      <td>0.269086</td>\n      <td>0.049639</td>\n      <td>0.954546</td>\n      <td>0.201576</td>\n      <td>0.961487</td>\n      <td>0.508347</td>\n      <td>...</td>\n      <td>0.916572</td>\n      <td>0.254563</td>\n      <td>0.930668</td>\n      <td>0.409699</td>\n      <td>0.167853</td>\n      <td>0.325146</td>\n      <td>0.062197</td>\n      <td>0.941091</td>\n      <td>0.242850</td>\n      <td>0.947143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WideDeep</td>\n      <td>TabMlp</td>\n      <td>0.507421</td>\n      <td>0.257476</td>\n      <td>0.370808</td>\n      <td>0.070433</td>\n      <td>0.908686</td>\n      <td>0.272293</td>\n      <td>0.915921</td>\n      <td>0.526612</td>\n      <td>...</td>\n      <td>0.910470</td>\n      <td>0.323880</td>\n      <td>0.921738</td>\n      <td>0.534130</td>\n      <td>0.285295</td>\n      <td>0.419972</td>\n      <td>0.081513</td>\n      <td>0.899874</td>\n      <td>0.354550</td>\n      <td>0.905366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AutoGluon</td>\n      <td>Linear Regression</td>\n      <td>0.492177</td>\n      <td>0.242239</td>\n      <td>0.360783</td>\n      <td>0.066718</td>\n      <td>0.914090</td>\n      <td>0.239442</td>\n      <td>0.914090</td>\n      <td>0.573398</td>\n      <td>...</td>\n      <td>0.893855</td>\n      <td>0.373830</td>\n      <td>0.894028</td>\n      <td>0.493568</td>\n      <td>0.243609</td>\n      <td>0.387519</td>\n      <td>0.073325</td>\n      <td>0.914504</td>\n      <td>0.327456</td>\n      <td>0.914646</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary classification\n",
    "\n",
    "As a showcase for binary classification, we use the Adult dataset from UCI datasets. Note that the Adult dataset has a individual testing set, which will be discussed in the \"Inference on an upcoming dataset\" part."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://archive.ics.uci.edu/static/public/2/adult.zip to /tmp/tmpqij93vth/data/Adult.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlluo/hdd/tabular_ensemble/tabensemb/config/user_config.py:226: UserWarning: There exists .test file(s) ['adult.test'] which should be used for final metrics. The .zip file isleft for the user to process.\n",
      "  warnings.warn(\n",
      "/home/xlluo/hdd/tabular_ensemble/tabensemb/utils/utils.py:315: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(StringIO(s), names=names, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project will be saved to /tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig\n",
      "Dataset size: 19536 6512 6513\n",
      "Data saved to /tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig (data.csv and tabular_data.csv).\n",
      "\n",
      "-------------Run PytorchTabular-------------\n",
      "\n",
      "Training Category Embedding\n",
      "Global seed set to 42\n",
      "2023-08-03 20:51:09,706 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-08-03 20:51:09,707 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "2023-08-03 20:51:09,765 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-08-03 20:51:09,801 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-08-03 20:51:09,825 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | _backbone        | CategoryEmbeddingBackbone | 18.5 K\n",
      "1 | _embedding_layer | Embedding1dLayer          | 1.4 K \n",
      "2 | head             | LinearHead                | 66    \n",
      "3 | loss             | CrossEntropyLoss          | 0     \n",
      "---------------------------------------------------------------\n",
      "20.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.0 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n",
      "Epoch: 1/300, Train loss: 0.4666, Val loss: 0.3794, Min val loss: 0.3794, Epoch time: 0.421s.\n",
      "Epoch: 20/300, Train loss: 0.3111, Val loss: 0.3181, Min val loss: 0.3174, Epoch time: 0.387s.\n",
      "Epoch: 40/300, Train loss: 0.2977, Val loss: 0.3207, Min val loss: 0.3152, Epoch time: 0.361s.\n",
      "Epoch: 60/300, Train loss: 0.2869, Val loss: 0.3249, Min val loss: 0.3152, Epoch time: 0.359s.\n",
      "Epoch: 80/300, Train loss: 0.2769, Val loss: 0.3314, Min val loss: 0.3152, Epoch time: 0.467s.\n",
      "Epoch: 100/300, Train loss: 0.2683, Val loss: 0.3416, Min val loss: 0.3152, Epoch time: 0.368s.\n",
      "Epoch: 120/300, Train loss: 0.2624, Val loss: 0.3487, Min val loss: 0.3152, Epoch time: 0.326s.\n",
      "2023-08-03 20:51:59,169 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-08-03 20:51:59,170 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/xlluo/anaconda3/envs/mlfatigue/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "Training log_loss loss: 0.28815\n",
      "Validation log_loss loss: 0.31522\n",
      "Testing log_loss loss: 0.31055\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------PytorchTabular End-------------\n",
      "\n",
      "\n",
      "-------------Run WideDeep-------------\n",
      "\n",
      "Training TabMlp\n",
      "Epoch: 1/300, Train loss: 0.5206, Val loss: 0.4274, Min val loss: 0.4274\n",
      "Epoch: 21/300, Train loss: 0.3145, Val loss: 0.3161, Min val loss: 0.3161\n",
      "Epoch: 41/300, Train loss: 0.3063, Val loss: 0.3191, Min val loss: 0.3161\n",
      "Epoch: 61/300, Train loss: 0.2980, Val loss: 0.3210, Min val loss: 0.3161\n",
      "Epoch: 81/300, Train loss: 0.2911, Val loss: 0.3225, Min val loss: 0.3161\n",
      "Epoch: 101/300, Train loss: 0.2824, Val loss: 0.3269, Min val loss: 0.3161\n",
      "Epoch: 121/300, Train loss: 0.2765, Val loss: 0.3291, Min val loss: 0.3161\n",
      "Epoch 00121: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00121: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Training log_loss loss: 0.30075\n",
      "Validation log_loss loss: 0.31724\n",
      "Testing log_loss loss: 0.31123\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------WideDeep End-------------\n",
      "\n",
      "\n",
      "-------------Run AutoGluon-------------\n",
      "\n",
      "Training Linear Regression\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig/AutoGluon/Linear Regression/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.17\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Dec 13 20:27:58 CST 2021\n",
      "Train Data Rows:    19536\n",
      "Train Data Columns: 14\n",
      "Tuning Data Rows:    6512\n",
      "Tuning Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting PipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9321.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.07 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['education', 'marital-status', 'native-country', 'occupation', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['education', 'marital-status', 'native-country', 'occupation', 'race', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "Fitting 1 L1 models ...\n",
      "Hyperparameter tuning model: LinearModel_BAG_L1 ...\n",
      "\tNo hyperparameter search space specified for LinearModel_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Fitted model: LinearModel_BAG_L1 ...\n",
      "\t0.8442\t = Validation score   (accuracy)\n",
      "\t2.89s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8414\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.1s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig/AutoGluon/Linear Regression/\")\n",
      "Training log_loss loss: 0.32821\n",
      "Validation log_loss loss: 0.33576\n",
      "Testing log_loss loss: 0.32834\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------AutoGluon End-------------\n",
      "\n",
      "PytorchTabular metrics\n",
      "Category Embedding 1/1\n",
      "WideDeep metrics\n",
      "TabMlp 1/1\n",
      "AutoGluon metrics\n",
      "Linear Regression 1/1\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/adult/2023-08-03-20-51-08-0_UserInputConfig/trainer.pkl')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Program               Model  Training F1_SCORE  \\\n0       AutoGluon   Linear Regression           0.649959   \n1        WideDeep              TabMlp           0.694051   \n2  PytorchTabular  Category Embedding           0.708106   \n\n   Training PRECISION_SCORE  Training RECALL_SCORE  Training JACCARD_SCORE  \\\n0                  0.719298               0.592813                0.481437   \n1                  0.730498               0.661067                0.531453   \n2                  0.742191               0.677015                0.548115   \n\n   Training ACCURACY_SCORE  Training BALANCED_ACCURACY_SCORE  \\\n0                 0.846284                          0.759732   \n1                 0.859695                          0.791870   \n2                 0.865633                          0.801226   \n\n   Training COHEN_KAPPA_SCORE  Training HAMMING_LOSS  ...  \\\n0                    0.552647               0.153716  ...   \n1                    0.603321               0.140305  ...   \n2                    0.621075               0.134367  ...   \n\n   Validation ACCURACY_SCORE  Validation BALANCED_ACCURACY_SCORE  \\\n0                   0.841370                            0.755397   \n1                   0.852426                            0.783820   \n2                   0.851044                            0.780948   \n\n   Validation COHEN_KAPPA_SCORE  Validation HAMMING_LOSS  \\\n0                      0.540607                 0.158630   \n1                      0.584325                 0.147574   \n2                      0.579583                 0.148956   \n\n   Validation MATTHEWS_CORRCOEF  Validation ZERO_ONE_LOSS  \\\n0                      0.544061                  0.158630   \n1                      0.585265                  0.147574   \n2                      0.580653                  0.148956   \n\n   Validation ROC_AUC_SCORE  Validation LOG_LOSS  Validation BRIER_SCORE_LOSS  \\\n0                  0.896542             0.335764                     0.108401   \n1                  0.908941             0.317243                     0.101578   \n2                  0.909818             0.315222                     0.101306   \n\n   Validation AVERAGE_PRECISION_SCORE  \n0                            0.848356  \n1                            0.868427  \n2                            0.869300  \n\n[3 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Model</th>\n      <th>Training F1_SCORE</th>\n      <th>Training PRECISION_SCORE</th>\n      <th>Training RECALL_SCORE</th>\n      <th>Training JACCARD_SCORE</th>\n      <th>Training ACCURACY_SCORE</th>\n      <th>Training BALANCED_ACCURACY_SCORE</th>\n      <th>Training COHEN_KAPPA_SCORE</th>\n      <th>Training HAMMING_LOSS</th>\n      <th>...</th>\n      <th>Validation ACCURACY_SCORE</th>\n      <th>Validation BALANCED_ACCURACY_SCORE</th>\n      <th>Validation COHEN_KAPPA_SCORE</th>\n      <th>Validation HAMMING_LOSS</th>\n      <th>Validation MATTHEWS_CORRCOEF</th>\n      <th>Validation ZERO_ONE_LOSS</th>\n      <th>Validation ROC_AUC_SCORE</th>\n      <th>Validation LOG_LOSS</th>\n      <th>Validation BRIER_SCORE_LOSS</th>\n      <th>Validation AVERAGE_PRECISION_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AutoGluon</td>\n      <td>Linear Regression</td>\n      <td>0.649959</td>\n      <td>0.719298</td>\n      <td>0.592813</td>\n      <td>0.481437</td>\n      <td>0.846284</td>\n      <td>0.759732</td>\n      <td>0.552647</td>\n      <td>0.153716</td>\n      <td>...</td>\n      <td>0.841370</td>\n      <td>0.755397</td>\n      <td>0.540607</td>\n      <td>0.158630</td>\n      <td>0.544061</td>\n      <td>0.158630</td>\n      <td>0.896542</td>\n      <td>0.335764</td>\n      <td>0.108401</td>\n      <td>0.848356</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WideDeep</td>\n      <td>TabMlp</td>\n      <td>0.694051</td>\n      <td>0.730498</td>\n      <td>0.661067</td>\n      <td>0.531453</td>\n      <td>0.859695</td>\n      <td>0.791870</td>\n      <td>0.603321</td>\n      <td>0.140305</td>\n      <td>...</td>\n      <td>0.852426</td>\n      <td>0.783820</td>\n      <td>0.584325</td>\n      <td>0.147574</td>\n      <td>0.585265</td>\n      <td>0.147574</td>\n      <td>0.908941</td>\n      <td>0.317243</td>\n      <td>0.101578</td>\n      <td>0.868427</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PytorchTabular</td>\n      <td>Category Embedding</td>\n      <td>0.708106</td>\n      <td>0.742191</td>\n      <td>0.677015</td>\n      <td>0.548115</td>\n      <td>0.865633</td>\n      <td>0.801226</td>\n      <td>0.621075</td>\n      <td>0.134367</td>\n      <td>...</td>\n      <td>0.851044</td>\n      <td>0.780948</td>\n      <td>0.579583</td>\n      <td>0.148956</td>\n      <td>0.580653</td>\n      <td>0.148956</td>\n      <td>0.909818</td>\n      <td>0.315222</td>\n      <td>0.101306</td>\n      <td>0.869300</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 44 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(device=device)\n",
    "cfg = UserConfig.from_uci(\"Adult\", sep=\", \")\n",
    "trainer.load_config(cfg)\n",
    "trainer.load_data()\n",
    "models = [\n",
    "    PytorchTabular(trainer, model_subset=[\"Category Embedding\"]),\n",
    "    WideDeep(trainer, model_subset=[\"TabMlp\"]),\n",
    "    AutoGluon(trainer, model_subset=[\"Linear Regression\"]),\n",
    "]\n",
    "trainer.add_modelbases(models)\n",
    "trainer.train(stderr_to_stdout=True)\n",
    "trainer.get_leaderboard()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiclass classification\n",
    "\n",
    "Iris is a famous multiclass classification task. It is also loaded from UCI datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://archive.ics.uci.edu/static/public/53/iris.zip to /tmp/tmpqij93vth/data/Iris.zip\n",
      "Project will be saved to /tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig\n",
      "Dataset size: 90 30 30\n",
      "Data saved to /tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig (data.csv and tabular_data.csv).\n",
      "\n",
      "-------------Run PytorchTabular-------------\n",
      "\n",
      "Training Category Embedding\n",
      "Global seed set to 42\n",
      "2023-08-03 20:52:30,779 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-08-03 20:52:30,780 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "2023-08-03 20:52:30,790 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-08-03 20:52:30,801 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-08-03 20:52:30,812 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | _backbone        | CategoryEmbeddingBackbone | 11.0 K\n",
      "1 | _embedding_layer | Embedding1dLayer          | 8     \n",
      "2 | head             | LinearHead                | 99    \n",
      "3 | loss             | CrossEntropyLoss          | 0     \n",
      "---------------------------------------------------------------\n",
      "11.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.1 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "Epoch: 1/300, Train loss: 1.7917, Val loss: 1.4287, Min val loss: 1.4287, Epoch time: 0.011s.\n",
      "Epoch: 20/300, Train loss: 0.3055, Val loss: 0.6197, Min val loss: 0.6197, Epoch time: 0.008s.\n",
      "Epoch: 40/300, Train loss: 0.2105, Val loss: 0.5668, Min val loss: 0.5668, Epoch time: 0.008s.\n",
      "Epoch: 60/300, Train loss: 0.1510, Val loss: 0.5234, Min val loss: 0.5234, Epoch time: 0.008s.\n",
      "Epoch: 80/300, Train loss: 0.1741, Val loss: 0.5314, Min val loss: 0.5216, Epoch time: 0.008s.\n",
      "Epoch: 100/300, Train loss: 0.0870, Val loss: 0.4985, Min val loss: 0.4853, Epoch time: 0.008s.\n",
      "Epoch: 120/300, Train loss: 0.0437, Val loss: 0.5143, Min val loss: 0.4853, Epoch time: 0.008s.\n",
      "Epoch: 140/300, Train loss: 0.0248, Val loss: 0.4864, Min val loss: 0.4844, Epoch time: 0.008s.\n",
      "Epoch: 160/300, Train loss: 0.0663, Val loss: 0.5182, Min val loss: 0.4506, Epoch time: 0.007s.\n",
      "Epoch: 180/300, Train loss: 0.0457, Val loss: 0.5648, Min val loss: 0.4506, Epoch time: 0.008s.\n",
      "Epoch: 200/300, Train loss: 0.0188, Val loss: 0.4554, Min val loss: 0.4319, Epoch time: 0.008s.\n",
      "Epoch: 220/300, Train loss: 0.0421, Val loss: 0.4980, Min val loss: 0.4269, Epoch time: 0.008s.\n",
      "Epoch: 240/300, Train loss: 0.0202, Val loss: 0.4948, Min val loss: 0.4187, Epoch time: 0.008s.\n",
      "Epoch: 260/300, Train loss: 0.0269, Val loss: 0.4776, Min val loss: 0.4187, Epoch time: 0.008s.\n",
      "Epoch: 280/300, Train loss: 0.0621, Val loss: 0.4086, Min val loss: 0.3670, Epoch time: 0.008s.\n",
      "Epoch: 300/300, Train loss: 0.0098, Val loss: 0.4748, Min val loss: 0.3670, Epoch time: 0.008s.\n",
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n",
      "2023-08-03 20:52:33,746 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-08-03 20:52:33,746 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/xlluo/anaconda3/envs/mlfatigue/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "Training log_loss loss: 0.01391\n",
      "Validation log_loss loss: 0.36698\n",
      "Testing log_loss loss: 0.14373\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------PytorchTabular End-------------\n",
      "\n",
      "\n",
      "-------------Run WideDeep-------------\n",
      "\n",
      "Training TabMlp\n",
      "Epoch: 1/300, Train loss: 1.0850, Val loss: 1.0164, Min val loss: 1.0164\n",
      "Epoch: 21/300, Train loss: 0.3373, Val loss: 0.5153, Min val loss: 0.5153\n",
      "Epoch: 41/300, Train loss: 0.1735, Val loss: 0.3780, Min val loss: 0.3780\n",
      "Epoch: 61/300, Train loss: 0.1253, Val loss: 0.3279, Min val loss: 0.3165\n",
      "Epoch: 81/300, Train loss: 0.0960, Val loss: 0.3603, Min val loss: 0.2951\n",
      "Epoch: 101/300, Train loss: 0.1037, Val loss: 0.3682, Min val loss: 0.2951\n",
      "Epoch: 121/300, Train loss: 0.1171, Val loss: 0.3525, Min val loss: 0.2951\n",
      "Epoch: 141/300, Train loss: 0.0503, Val loss: 0.3754, Min val loss: 0.2951\n",
      "Epoch: 161/300, Train loss: 0.0421, Val loss: 0.3265, Min val loss: 0.2951\n",
      "Epoch 00167: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00167: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Training log_loss loss: 0.06156\n",
      "Validation log_loss loss: 0.29513\n",
      "Testing log_loss loss: 0.11595\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------WideDeep End-------------\n",
      "\n",
      "\n",
      "-------------Run AutoGluon-------------\n",
      "\n",
      "Training Linear Regression\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig/AutoGluon/Linear Regression/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.17\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Dec 13 20:27:58 CST 2021\n",
      "Train Data Rows:    90\n",
      "Train Data Columns: 4\n",
      "Tuning Data Rows:    30\n",
      "Tuning Data Columns: 4\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting PipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9313.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "Fitting 1 L1 models ...\n",
      "Hyperparameter tuning model: LinearModel_BAG_L1 ...\n",
      "\tNo hyperparameter search space specified for LinearModel_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Fitted model: LinearModel_BAG_L1 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8333\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.98s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig/AutoGluon/Linear Regression/\")\n",
      "Training log_loss loss: 0.15149\n",
      "Validation log_loss loss: 0.30651\n",
      "Testing log_loss loss: 0.16492\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig/trainer.pkl')\n",
      "\n",
      "-------------AutoGluon End-------------\n",
      "\n",
      "PytorchTabular metrics\n",
      "Category Embedding 1/1\n",
      "WideDeep metrics\n",
      "TabMlp 1/1\n",
      "AutoGluon metrics\n",
      "Linear Regression 1/1\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-30-0_UserInputConfig/trainer.pkl')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Program               Model  Training ACCURACY_SCORE  \\\n0  PytorchTabular  Category Embedding                      1.0   \n1        WideDeep              TabMlp                      1.0   \n2       AutoGluon   Linear Regression                      1.0   \n\n   Training BALANCED_ACCURACY_SCORE  Training COHEN_KAPPA_SCORE  \\\n0                               1.0                         1.0   \n1                               1.0                         1.0   \n2                               1.0                         1.0   \n\n   Training HAMMING_LOSS  Training MATTHEWS_CORRCOEF  Training ZERO_ONE_LOSS  \\\n0                    0.0                         1.0                     0.0   \n1                    0.0                         1.0                     0.0   \n2                    0.0                         1.0                     0.0   \n\n   Training PRECISION_SCORE_MACRO  Training PRECISION_SCORE_MICRO  ...  \\\n0                             1.0                             1.0  ...   \n1                             1.0                             1.0  ...   \n2                             1.0                             1.0  ...   \n\n   Validation F1_SCORE_MICRO  Validation F1_SCORE_WEIGHTED  \\\n0                   0.833333                      0.837232   \n1                   0.833333                      0.837232   \n2                   0.833333                      0.837232   \n\n   Validation JACCARD_SCORE_MACRO  Validation JACCARD_SCORE_MICRO  \\\n0                        0.756944                        0.714286   \n1                        0.756944                        0.714286   \n2                        0.756944                        0.714286   \n\n   Validation JACCARD_SCORE_WEIGHTED  Validation TOP_K_ACCURACY_SCORE  \\\n0                           0.732639                              1.0   \n1                           0.732639                              1.0   \n2                           0.732639                              1.0   \n\n   Validation LOG_LOSS  Validation ROC_AUC_SCORE_OVR_MACRO  \\\n0             0.366983                            0.974891   \n1             0.295129                            0.979747   \n2             0.306514                            0.986498   \n\n   Validation ROC_AUC_SCORE_OVR_WEIGHTED  Validation ROC_AUC_SCORE_OVO  \n0                               0.971616                      0.976042  \n1                               0.977576                      0.980833  \n2                               0.985051                      0.987222  \n\n[3 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Model</th>\n      <th>Training ACCURACY_SCORE</th>\n      <th>Training BALANCED_ACCURACY_SCORE</th>\n      <th>Training COHEN_KAPPA_SCORE</th>\n      <th>Training HAMMING_LOSS</th>\n      <th>Training MATTHEWS_CORRCOEF</th>\n      <th>Training ZERO_ONE_LOSS</th>\n      <th>Training PRECISION_SCORE_MACRO</th>\n      <th>Training PRECISION_SCORE_MICRO</th>\n      <th>...</th>\n      <th>Validation F1_SCORE_MICRO</th>\n      <th>Validation F1_SCORE_WEIGHTED</th>\n      <th>Validation JACCARD_SCORE_MACRO</th>\n      <th>Validation JACCARD_SCORE_MICRO</th>\n      <th>Validation JACCARD_SCORE_WEIGHTED</th>\n      <th>Validation TOP_K_ACCURACY_SCORE</th>\n      <th>Validation LOG_LOSS</th>\n      <th>Validation ROC_AUC_SCORE_OVR_MACRO</th>\n      <th>Validation ROC_AUC_SCORE_OVR_WEIGHTED</th>\n      <th>Validation ROC_AUC_SCORE_OVO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PytorchTabular</td>\n      <td>Category Embedding</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.833333</td>\n      <td>0.837232</td>\n      <td>0.756944</td>\n      <td>0.714286</td>\n      <td>0.732639</td>\n      <td>1.0</td>\n      <td>0.366983</td>\n      <td>0.974891</td>\n      <td>0.971616</td>\n      <td>0.976042</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WideDeep</td>\n      <td>TabMlp</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.833333</td>\n      <td>0.837232</td>\n      <td>0.756944</td>\n      <td>0.714286</td>\n      <td>0.732639</td>\n      <td>1.0</td>\n      <td>0.295129</td>\n      <td>0.979747</td>\n      <td>0.977576</td>\n      <td>0.980833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AutoGluon</td>\n      <td>Linear Regression</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.833333</td>\n      <td>0.837232</td>\n      <td>0.756944</td>\n      <td>0.714286</td>\n      <td>0.732639</td>\n      <td>1.0</td>\n      <td>0.306514</td>\n      <td>0.986498</td>\n      <td>0.985051</td>\n      <td>0.987222</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(device=device)\n",
    "cfg = UserConfig.from_uci(\"Iris\", datafile_name=\"iris\")\n",
    "trainer.load_config(cfg)\n",
    "trainer.load_data()\n",
    "models = [\n",
    "    PytorchTabular(trainer, model_subset=[\"Category Embedding\"]),\n",
    "    WideDeep(trainer, model_subset=[\"TabMlp\"]),\n",
    "    AutoGluon(trainer, model_subset=[\"Linear Regression\"]),\n",
    "]\n",
    "trainer.add_modelbases(models)\n",
    "trainer.train(stderr_to_stdout=True)\n",
    "trainer.get_leaderboard()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using a configuration file\n",
    "\n",
    "In the above introduction, we use UCI datasets whose configuration is automatically generated. The configuration can also be loaded from a local `.py` or `.json` file. To run a minimum example, we provide a randomly generated sample dataset (`data/sample.csv`) and its configuration file (`configs/sample.py`) in the repository. See \"Dataset and configuration\" for detailed introduction of configuration files.\n",
    "\n",
    "`tabensemb` uses paths relative to the current directory. For different IDEs (PyCharm, VSCode, etc.), the directory can be different. Set default paths to desired ones."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../../../../\"\n",
    "tabensemb.setting[\"default_config_path\"] = path + \"configs\"\n",
    "tabensemb.setting[\"default_data_path\"] = path + \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the configuration file `sample.py` using `Trainer.load_config`, which automatically searches the file in the current directory and `tabensemb.setting[\"default_config_path\"]`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project will be saved to /tmp/tmpqij93vth/output/iris/2023-08-03-20-52-36-0_sample\n",
      "Dataset size: 153 51 52\n",
      "Data saved to /tmp/tmpqij93vth/output/iris/2023-08-03-20-52-36-0_sample (data.csv and tabular_data.csv).\n"
     ]
    }
   ],
   "source": [
    "trainer.load_config(\"sample\")\n",
    "trainer.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then initialize models:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "trainer.clear_modelbase()\n",
    "models = [\n",
    "    PytorchTabular(trainer, model_subset=[\"Category Embedding\"])\n",
    "]\n",
    "trainer.add_modelbases(models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Optional*: For a quick development test, changing the following global setting significantly reduces training time."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "tabensemb.setting[\"debug_mode\"] = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------Run PytorchTabular-------------\n",
      "\n",
      "Training Category Embedding\n",
      "Global seed set to 42\n",
      "2023-08-03 20:52:37,112 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-08-03 20:52:37,112 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-08-03 20:52:37,126 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-08-03 20:52:37,142 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-08-03 20:52:37,155 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | _backbone        | CategoryEmbeddingBackbone | 12.3 K\n",
      "1 | _embedding_layer | Embedding1dLayer          | 64    \n",
      "2 | head             | LinearHead                | 33    \n",
      "3 | loss             | MSELoss                   | 0     \n",
      "---------------------------------------------------------------\n",
      "12.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.4 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n",
      "Epoch: 1/2, Train loss: 33183.6562, Val loss: 22223.0391, Min val loss: 22223.0391, Epoch time: 0.014s.\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "2023-08-03 20:52:37,233 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-08-03 20:52:37,234 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/xlluo/anaconda3/envs/mlfatigue/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "Training mse loss: 33085.08332\n",
      "Validation mse loss: 22182.62020\n",
      "Testing mse loss: 29810.51081\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-36-0_sample/trainer.pkl')\n",
      "\n",
      "-------------PytorchTabular End-------------\n",
      "\n",
      "PytorchTabular metrics\n",
      "Category Embedding 1/1\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='/tmp/tmpqij93vth/output/iris/2023-08-03-20-52-36-0_sample/trainer.pkl')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Program               Model  Training RMSE  Training MSE  \\\n0  PytorchTabular  Category Embedding     181.893055  33085.083317   \n\n   Training MAE  Training MAPE  Training R2  Training MEDIAN_ABSOLUTE_ERROR  \\\n0    145.409737       1.055588    -0.004359                      121.139843   \n\n   Training EXPLAINED_VARIANCE_SCORE  Testing RMSE  ...  Testing R2  \\\n0                           0.001236    172.657206  ...   -0.005851   \n\n   Testing MEDIAN_ABSOLUTE_ERROR  Testing EXPLAINED_VARIANCE_SCORE  \\\n0                     118.665751                         -0.001657   \n\n   Validation RMSE  Validation MSE  Validation MAE  Validation MAPE  \\\n0        148.93831      22182.6202      121.146176          1.00906   \n\n   Validation R2  Validation MEDIAN_ABSOLUTE_ERROR  \\\n0      -0.001817                         92.916794   \n\n   Validation EXPLAINED_VARIANCE_SCORE  \n0                             0.001214  \n\n[1 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Model</th>\n      <th>Training RMSE</th>\n      <th>Training MSE</th>\n      <th>Training MAE</th>\n      <th>Training MAPE</th>\n      <th>Training R2</th>\n      <th>Training MEDIAN_ABSOLUTE_ERROR</th>\n      <th>Training EXPLAINED_VARIANCE_SCORE</th>\n      <th>Testing RMSE</th>\n      <th>...</th>\n      <th>Testing R2</th>\n      <th>Testing MEDIAN_ABSOLUTE_ERROR</th>\n      <th>Testing EXPLAINED_VARIANCE_SCORE</th>\n      <th>Validation RMSE</th>\n      <th>Validation MSE</th>\n      <th>Validation MAE</th>\n      <th>Validation MAPE</th>\n      <th>Validation R2</th>\n      <th>Validation MEDIAN_ABSOLUTE_ERROR</th>\n      <th>Validation EXPLAINED_VARIANCE_SCORE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PytorchTabular</td>\n      <td>Category Embedding</td>\n      <td>181.893055</td>\n      <td>33085.083317</td>\n      <td>145.409737</td>\n      <td>1.055588</td>\n      <td>-0.004359</td>\n      <td>121.139843</td>\n      <td>0.001236</td>\n      <td>172.657206</td>\n      <td>...</td>\n      <td>-0.005851</td>\n      <td>118.665751</td>\n      <td>-0.001657</td>\n      <td>148.93831</td>\n      <td>22182.6202</td>\n      <td>121.146176</td>\n      <td>1.00906</td>\n      <td>-0.001817</td>\n      <td>92.916794</td>\n      <td>0.001214</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(stderr_to_stdout=True)\n",
    "trainer.get_leaderboard()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the temporary directory of the notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "temp_path.cleanup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}