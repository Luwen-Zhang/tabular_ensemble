{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Running model bases on a sample dataset\n",
    "\n",
    "Tabular Ensemble (`tabensemb`) is a benchmark platform for tabular prediction tasks. We support three well-established model bases as baselines:\n",
    "\n",
    "* `autogluon`: [Link](https://github.com/autogluon/autogluon)\n",
    "\n",
    "* `pytorch_widedeep`: [Link](https://github.com/jrzaurin/pytorch-widedeep)\n",
    "\n",
    "* `pytorch_tabular`: [Link](https://github.com/manujosephv/pytorch_tabular)\n",
    "\n",
    "Users are able to run benchmarks on customized datasets using customized preprocessing steps, and implement customized models in the framework to run and compare their performance with baselines within a consistent procedure.\n",
    "\n",
    "In this part, a minimum example is performed to show the basic functionality of the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading packages\n",
    "\n",
    "To run a minimum example, we provide a randomly generated sample dataset (`data/sample.csv`) and its configuration file (`configs/sample.py`) in the repository. First, import necessary modules.\n",
    "\n",
    "`tabensemb` uses paths relative to the current directory. For different IDEs (PyCharm, VSCode, etc.), the directory can be different. Set default paths to desired ones.\n",
    "\n",
    "Then check the validity of `CUDA` and determine the training device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tabensemb.trainer import Trainer\n",
    "from tabensemb.model import *\n",
    "import tabensemb\n",
    "import os\n",
    "\n",
    "prefix = \"../../../../\"\n",
    "tabensemb.setting[\"default_output_path\"] = prefix + \"output\"\n",
    "tabensemb.setting[\"default_config_path\"] = prefix + \"configs\"\n",
    "tabensemb.setting[\"default_data_path\"] = prefix + \"data\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuring a `Trainer`\n",
    "\n",
    "Create a `Trainer`, which acts as a bridge of data and models and provides some useful ultilities.\n",
    "\n",
    "Load the configuration file `sample.py` using `Trainer.load_config`, which automatically searches the file in the current directory and `tabensemb.setting[\"default_config_path\"]`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project will be saved to ../../../../output/sample/2023-07-30-13-33-54-0_sample\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(device=device)\n",
    "trainer.load_config(\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Optional*: We provide a useful `Logging` class to record all outputs to a file located in the above project root, so that users can review the training process. This step is optional but we strongly recommend using it.\n",
    "\n",
    "`Trainer.project_root` is the output directory of the `trainer`, and here we log all `stdout` and `stderr` to `log.txt` in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tabensemb.utils import Logging\n",
    "log = Logging()\n",
    "log.enter(os.path.join(trainer.project_root, \"log.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Viewing configurations\n",
    "\n",
    "We can view the summary of the current environment, including devices/Python version, the loaded configuration file `configs/sample.py`, and global settings of `tabensemb`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:\n",
      "{\n",
      "\t'System': 'Linux',\n",
      "\t'Node name': 'xlluo-WS',\n",
      "\t'System release': '5.15.6-custom',\n",
      "\t'System version': '#1 SMP Mon Dec 13 20:27:58 CST 2021',\n",
      "\t'Machine architecture': 'x86_64',\n",
      "\t'Processor architecture': 'x86_64',\n",
      "\t'Processor model': '11th Gen Intel(R) Core(TM) i9-11900K @ 3.50GHz',\n",
      "\t'Physical cores': 8,\n",
      "\t'Total cores': 16,\n",
      "\t'Max core frequency': '5150.00Mhz',\n",
      "\t'Total memory': '31.20GB',\n",
      "\t'Python version': '3.8.17',\n",
      "\t'Python implementation': 'CPython',\n",
      "\t'Python compiler': 'GCC 11.2.0',\n",
      "\t'Cuda availability': True,\n",
      "\t'GPU devices': [\n",
      "\t\t'NVIDIA GeForce RTX 3090'\n",
      "\t]\n",
      "}\n",
      "Configurations:\n",
      "{\n",
      "\t'database': 'sample',\n",
      "\t'bayes_opt': False,\n",
      "\t'bayes_calls': 50,\n",
      "\t'bayes_epoch': 30,\n",
      "\t'patience': 100,\n",
      "\t'epoch': 300,\n",
      "\t'lr': 0.001,\n",
      "\t'weight_decay': 1e-09,\n",
      "\t'batch_size': 1024,\n",
      "\t'layers': [\n",
      "\t\t64,\n",
      "\t\t128,\n",
      "\t\t256,\n",
      "\t\t128,\n",
      "\t\t64\n",
      "\t],\n",
      "\t'SPACEs': {\n",
      "\t\t'lr': {\n",
      "\t\t\t'type': 'Real',\n",
      "\t\t\t'low': 0.0001,\n",
      "\t\t\t'high': 0.05,\n",
      "\t\t\t'prior': 'log-uniform'\n",
      "\t\t},\n",
      "\t\t'weight_decay': {\n",
      "\t\t\t'type': 'Real',\n",
      "\t\t\t'low': 1e-09,\n",
      "\t\t\t'high': 0.05,\n",
      "\t\t\t'prior': 'log-uniform'\n",
      "\t\t},\n",
      "\t\t'batch_size': {\n",
      "\t\t\t'type': 'Categorical',\n",
      "\t\t\t'categories': [\n",
      "\t\t\t\t64,\n",
      "\t\t\t\t128,\n",
      "\t\t\t\t256,\n",
      "\t\t\t\t512,\n",
      "\t\t\t\t1024,\n",
      "\t\t\t\t2048\n",
      "\t\t\t]\n",
      "\t\t}\n",
      "\t},\n",
      "\t'data_splitter': 'RandomSplitter',\n",
      "\t'split_ratio': [\n",
      "\t\t0.6,\n",
      "\t\t0.2,\n",
      "\t\t0.2\n",
      "\t],\n",
      "\t'data_imputer': 'MissForestImputer',\n",
      "\t'data_processors': [\n",
      "\t\t(\n",
      "\t\t\t'CategoricalOrdinalEncoder',\n",
      "\t\t\t{\n",
      "\t\t\t}\n",
      "\t\t),\n",
      "\t\t(\n",
      "\t\t\t'NaNFeatureRemover',\n",
      "\t\t\t{\n",
      "\t\t\t}\n",
      "\t\t),\n",
      "\t\t(\n",
      "\t\t\t'VarianceFeatureSelector',\n",
      "\t\t\t{\n",
      "\t\t\t\t'thres': 1\n",
      "\t\t\t}\n",
      "\t\t),\n",
      "\t\t(\n",
      "\t\t\t'StandardScaler',\n",
      "\t\t\t{\n",
      "\t\t\t}\n",
      "\t\t)\n",
      "\t],\n",
      "\t'data_derivers': [\n",
      "\t],\n",
      "\t'feature_names_type': {\n",
      "\t\t'cont_0': 0,\n",
      "\t\t'cont_1': 0,\n",
      "\t\t'cont_2': 0,\n",
      "\t\t'cont_3': 0,\n",
      "\t\t'cont_4': 0,\n",
      "\t\t'cat_0': 1,\n",
      "\t\t'cat_1': 1,\n",
      "\t\t'cat_2': 1\n",
      "\t},\n",
      "\t'categorical_feature_names': [\n",
      "\t\t'cat_0',\n",
      "\t\t'cat_1',\n",
      "\t\t'cat_2'\n",
      "\t],\n",
      "\t'feature_types': [\n",
      "\t\t'Continuous',\n",
      "\t\t'Categorical',\n",
      "\t\t'Derived'\n",
      "\t],\n",
      "\t'label_name': [\n",
      "\t\t'target'\n",
      "\t]\n",
      "}\n",
      "Global settings:\n",
      "{\n",
      "\t'random_seed': 42,\n",
      "\t'low_memory': True,\n",
      "\t'verbose_per_epoch': 20,\n",
      "\t'test_with_no_grad': True,\n",
      "\t'debug_mode': False,\n",
      "\t'default_output_path': '../../../../output',\n",
      "\t'default_config_path': '../../../../configs',\n",
      "\t'default_data_path': '../../../../data',\n",
      "\t'warn_nan_metric': True\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trainer.summarize_setting()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data\n",
    "\n",
    "In the configuration summary above, the dataset file is defined by \"database\" under the `Configurations` category. `Trainer.load_data` automatically searches the file in the current directory and `tabensemb.setting[\"default_data_path\"]`. Now, load the dataset `data/sample.csv` into the `Trainer`. It will process the dataset and get ready for training models:\n",
    "\n",
    "1. Data splitting (training/validation/testing sets)\n",
    "2. Data imputation\n",
    "3. Data augmentation (for features)\n",
    "4. Data processing\n",
    "    * Data augmentation (for data points)\n",
    "    * Data filtering\n",
    "    * Feature selection\n",
    "    * Categorical encoding\n",
    "    * Data scaling\n",
    "    * etc.\n",
    "5. Data augmentation (for features, especially multi-modal features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 153 51 52\n",
      "Data saved to ../../../../output/sample/2023-07-30-13-33-54-0_sample (data.csv and tabular_data.csv).\n"
     ]
    }
   ],
   "source": [
    "trainer.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initializing model bases\n",
    "\n",
    "Initialize model bases and add them to the `Trainer`. We only choose a subset of models in each model base for demonstration by passing the `model_subset` argument (without it, all available models will be trained)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    PytorchTabular(trainer, model_subset=[\"Category Embedding\"]),\n",
    "    WideDeep(trainer, model_subset=[\"TabMlp\"]),\n",
    "    AutoGluon(trainer, model_subset=[\"Linear Regression\"]),\n",
    "]\n",
    "trainer.add_modelbases(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Optional*: For a quick development test, changing the following global setting significantly reduces training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tabensemb.setting[\"debug_mode\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Start training\n",
    "\n",
    "Now train the model bases. The argument `stderr_to_stdout` will redirect warnings and loggings to `stdout` and makes records in the notebook clean. After training finishes, check the leaderboard to see their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------Run PytorchTabular-------------\n",
      "\n",
      "Training Category Embedding\n",
      "Global seed set to 42\n",
      "2023-07-30 13:33:54,776 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-07-30 13:33:54,777 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-07-30 13:33:54,790 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-07-30 13:33:54,805 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-07-30 13:33:55,698 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | custom_loss      | MSELoss                   | 0     \n",
      "1 | _backbone        | CategoryEmbeddingBackbone | 12.3 K\n",
      "2 | _embedding_layer | Embedding1dLayer          | 64    \n",
      "3 | head             | LinearHead                | 33    \n",
      "---------------------------------------------------------------\n",
      "12.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.4 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n",
      "Epoch: 1/2, Train loss: 33183.6562, Val loss: 22223.0391, Min val loss: 22223.0391, Epoch time: 0.015s.\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "2023-07-30 13:33:56,648 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-07-30 13:33:56,649 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/xlluo/anaconda3/envs/mlfatigue/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v1.10.0. Please use `lightning_lite.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n",
      "Training MSE loss: 33085.08332, RMSE loss: 181.89305\n",
      "Validation MSE loss: 22182.62020, RMSE loss: 148.93831\n",
      "Testing MSE loss: 29810.51081, RMSE loss: 172.65721\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='../../../../output/sample/2023-07-30-13-33-54-0_sample/trainer.pkl')\n",
      "\n",
      "-------------PytorchTabular End-------------\n",
      "\n",
      "\n",
      "-------------Run WideDeep-------------\n",
      "\n",
      "Training TabMlp\n",
      "Epoch: 1/2, Train loss: 33208.6875, Val loss: 22258.0938, Min val loss: 22258.0938\n",
      "Restoring model weights from the end of the best epoch\n",
      "Training MSE loss: 33187.42470, RMSE loss: 182.17416\n",
      "Validation MSE loss: 22252.86468, RMSE loss: 149.17394\n",
      "Testing MSE loss: 29700.41624, RMSE loss: 172.33809\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='../../../../output/sample/2023-07-30-13-33-54-0_sample/trainer.pkl')\n",
      "\n",
      "-------------WideDeep End-------------\n",
      "\n",
      "\n",
      "-------------Run AutoGluon-------------\n",
      "\n",
      "Training Linear Regression\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"../../../../output/sample/2023-07-30-13-33-54-0_sample/AutoGluon/Linear Regression/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.8.17\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Dec 13 20:27:58 CST 2021\n",
      "Train Data Rows:    153\n",
      "Train Data Columns: 8\n",
      "Tuning Data Rows:    51\n",
      "Tuning Data Columns: 8\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting PipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21224.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tWarning: feature_metadata_in passed as input to fit_transform, but self.feature_metadata_in was already set. Ignoring feature_metadata_in.\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 5 | ['cont_0', 'cont_1', 'cont_2', 'cont_3', 'cont_4']\n",
      "\t\t('int', [])    : 2 | ['cat_1', 'cat_2']\n",
      "\t\t('object', []) : 1 | ['cat_0']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['cat_0', 'cat_1', 'cat_2']\n",
      "\t\t('float', [])    : 5 | ['cont_0', 'cont_1', 'cont_2', 'cont_3', 'cont_4']\n",
      "\t0.0s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "Fitting 1 L1 models ...\n",
      "Hyperparameter tuning model: LinearModel_BAG_L1 ...\n",
      "\tNo hyperparameter search space specified for LinearModel_BAG_L1. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Fitted model: LinearModel_BAG_L1 ...\n",
      "\t-124.8624\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-110.2535\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"../../../../output/sample/2023-07-30-13-33-54-0_sample/AutoGluon/Linear Regression/\")\n",
      "Training MSE loss: 13011.04803, RMSE loss: 114.06598\n",
      "Validation MSE loss: 12155.84262, RMSE loss: 110.25354\n",
      "Testing MSE loss: 19396.05863, RMSE loss: 139.26973\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='../../../../output/sample/2023-07-30-13-33-54-0_sample/trainer.pkl')\n",
      "\n",
      "-------------AutoGluon End-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(stderr_to_stdout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchTabular metrics\n",
      "Category Embedding 1/1\n",
      "WideDeep metrics\n",
      "TabMlp 1/1\n",
      "AutoGluon metrics\n",
      "Linear Regression 1/1\n",
      "Trainer saved. To load the trainer, run trainer = load_trainer(path='../../../../output/sample/2023-07-30-13-33-54-0_sample/trainer.pkl')\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Program               Model  Training RMSE  Training MSE  \\\n0       AutoGluon   Linear Regression     114.065981  13011.048027   \n1        WideDeep              TabMlp     182.174160  33187.424698   \n2  PytorchTabular  Category Embedding     181.893055  33085.083317   \n\n   Training MAE  Training MAPE  Training R2  Training RMSE_CONSERV  \\\n0     91.398513       2.686924     0.605025           12364.215662   \n1    145.805452       0.996663    -0.007466           31909.355406   \n2    145.409737       1.055588    -0.004359           31932.919579   \n\n   Testing RMSE   Testing MSE  Testing MAE  Testing MAPE  Testing R2  \\\n0    139.269733  19396.058633   119.072766      4.078846    0.345548   \n1    172.338087  29700.416239   132.766950      0.994150   -0.002136   \n2    172.657206  29810.510810   132.876842      0.970391   -0.005851   \n\n   Testing RMSE_CONSERV  Validation RMSE  Validation MSE  Validation MAE  \\\n0          11994.905098       110.253538    12155.842624       88.607594   \n1          23339.518145       149.173941    22252.864676      120.977058   \n2          23596.311604       148.938310    22182.620200      121.146176   \n\n   Validation MAPE  Validation R2  Validation RMSE_CONSERV  \n0         1.546470       0.451015             12189.700803  \n1         1.000998      -0.004989             29799.600759  \n2         1.009060      -0.001817             29044.712738  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Program</th>\n      <th>Model</th>\n      <th>Training RMSE</th>\n      <th>Training MSE</th>\n      <th>Training MAE</th>\n      <th>Training MAPE</th>\n      <th>Training R2</th>\n      <th>Training RMSE_CONSERV</th>\n      <th>Testing RMSE</th>\n      <th>Testing MSE</th>\n      <th>Testing MAE</th>\n      <th>Testing MAPE</th>\n      <th>Testing R2</th>\n      <th>Testing RMSE_CONSERV</th>\n      <th>Validation RMSE</th>\n      <th>Validation MSE</th>\n      <th>Validation MAE</th>\n      <th>Validation MAPE</th>\n      <th>Validation R2</th>\n      <th>Validation RMSE_CONSERV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AutoGluon</td>\n      <td>Linear Regression</td>\n      <td>114.065981</td>\n      <td>13011.048027</td>\n      <td>91.398513</td>\n      <td>2.686924</td>\n      <td>0.605025</td>\n      <td>12364.215662</td>\n      <td>139.269733</td>\n      <td>19396.058633</td>\n      <td>119.072766</td>\n      <td>4.078846</td>\n      <td>0.345548</td>\n      <td>11994.905098</td>\n      <td>110.253538</td>\n      <td>12155.842624</td>\n      <td>88.607594</td>\n      <td>1.546470</td>\n      <td>0.451015</td>\n      <td>12189.700803</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WideDeep</td>\n      <td>TabMlp</td>\n      <td>182.174160</td>\n      <td>33187.424698</td>\n      <td>145.805452</td>\n      <td>0.996663</td>\n      <td>-0.007466</td>\n      <td>31909.355406</td>\n      <td>172.338087</td>\n      <td>29700.416239</td>\n      <td>132.766950</td>\n      <td>0.994150</td>\n      <td>-0.002136</td>\n      <td>23339.518145</td>\n      <td>149.173941</td>\n      <td>22252.864676</td>\n      <td>120.977058</td>\n      <td>1.000998</td>\n      <td>-0.004989</td>\n      <td>29799.600759</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PytorchTabular</td>\n      <td>Category Embedding</td>\n      <td>181.893055</td>\n      <td>33085.083317</td>\n      <td>145.409737</td>\n      <td>1.055588</td>\n      <td>-0.004359</td>\n      <td>31932.919579</td>\n      <td>172.657206</td>\n      <td>29810.510810</td>\n      <td>132.876842</td>\n      <td>0.970391</td>\n      <td>-0.005851</td>\n      <td>23596.311604</td>\n      <td>148.938310</td>\n      <td>22182.620200</td>\n      <td>121.146176</td>\n      <td>1.009060</td>\n      <td>-0.001817</td>\n      <td>29044.712738</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}